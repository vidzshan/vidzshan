{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPx3IfCWS3op0Cg7jdgCySc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vidzshan/vidzshan/blob/main/bracemodule.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting Google Drive"
      ],
      "metadata": {
        "id": "9K0Ht4f2Rl7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "MOUNTPOINT = '/content/gdrive'\n",
        "DATADIR = os.path.join(MOUNTPOINT, 'My Drive', 'Colab Notebooks','Research')\n",
        "drive.mount(MOUNTPOINT)\n",
        "\n",
        "#Access the data\n",
        "#path = os.path.join(DATADIR, 'data')\n",
        "\n",
        "#save trained data results or modules\n",
        "#model.save(os.path.join(DATADIR, 'model.h5'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fwNGSF6RlEP",
        "outputId": "550df226-8247-4481-b11b-d0a3ac368eff"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4d6f31d"
      },
      "source": [
        "Here is the `requirements.txt` file with the packages you specified. You can use this file to install the dependencies for your project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dda4b19",
        "outputId": "a46d1934-92ce-4fbd-88a7-f38c7f44397d"
      },
      "source": [
        "%%writefile requirements.txt\n",
        "smplx\n",
        "pyrender\n",
        "trimesh\n",
        "torch-geometric"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "9RJyl7nkS4hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "CuDGaTSfNiL1",
        "outputId": "49acf992-56fd-48bc-9d62-448facac1bd8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-320300646.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#!pip install smplx pyrender trimesh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#!git clone https://github.com/vchoutas/smplx /content/smplx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0msmpl_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmplx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'smplx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neutral'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_pca\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_betas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_expression_coeffs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SMPL-X loaded successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Forward pass with correct tensor shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1367\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1353\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m                     )\n\u001b[0;32m-> 1355\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1356\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import smplx\n",
        "\n",
        "model_path = os.path.join(DATADIR, 'smplx_models','SMPLX_NEUTRAL_2020.npz')\n",
        "\n",
        "# Load BRACE keypoint sample\n",
        "keypoints_path = os.path.join(DATADIR, 'brace','manual_keypoints', '2011', '3rIk56dcBTM', 'img-001293.npz')\n",
        "keypoints_data = np.load(keypoints_path)\n",
        "keypoints = keypoints_data['coco_joints2d'][:, :2]  # Shape: [17, 2] for x, y coords\n",
        "\n",
        "# Install SMPL-X dependencies\n",
        "#!pip install smplx pyrender trimesh\n",
        "#!git clone https://github.com/vchoutas/smplx /content/smplx\n",
        "smpl_model = smplx.create(model_path=model_path, model_type='smplx', gender='neutral', use_pca=False, num_betas = 10, num_expression_coeffs=10).to('cuda')\n",
        "print(\"SMPL-X loaded successfully!\")\n",
        "# Forward pass with correct tensor shapes\n",
        "output = smpl_model(\n",
        "    betas=torch.zeros(1, 10).to('cuda'),\n",
        "    expression=torch.zeros(1, 10).to('cuda'),\n",
        "    body_pose=torch.zeros(1, 21*3).to('cuda'),  # 21 joints, 3D rotation each (not 21*6)\n",
        "    global_orient=torch.zeros(1, 3).to('cuda')   # Add global_orient [1, 3]\n",
        ")\n",
        "print(f\"Output vertices shape: {output.vertices.shape}\")  # Should be [1, 10475, 3]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this cell is responsible for loading, preprocessing, and structuring\n",
        "#the keypoint and audio data into a format suitable for training a\n",
        "#Graph Convolutional Network (GCN) model to classify dance types.\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GCNConv\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "# Load segments.csv\n",
        "segments = pd.read_csv(Path(DATADIR) / 'brace' / 'annotations' / 'segments.csv')\n",
        "sequences = segments.head(30)  # 30 sequences\n",
        "\n",
        "# Define COCO skeleton edges (17 joints)\n",
        "edge_index = torch.tensor([\n",
        "    [0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7],  # Head to arms\n",
        "    [1,8], [8,9], [9,10], [10,11], [8,12], [12,13], [13,14],  # Torso to legs\n",
        "    [0,15], [0,16]  # Nose to eyes\n",
        "], dtype=torch.long).t().contiguous()\n",
        "\n",
        "# Prepare data\n",
        "data_list = []\n",
        "for _, row in sequences.iterrows():\n",
        "    keypoints_file = Path(DATADIR) / 'brace' / 'dataset' / str(row['year']) / row['video_id'] / f\"{row['video_id']}_{row['start_frame']}-{row['end_frame']}_{row['dance_type']}.json.json\"\n",
        "    with open(keypoints_file, 'r') as f:\n",
        "        keypoints_dict = json.load(f)\n",
        "    keypoints_array = np.array([v['keypoints'] for v in keypoints_dict.values()])[:, :, :2]  # [frames, 17, 2]\n",
        "    box = list(keypoints_dict.values())[0]['box']  # [x, y, w, h, score]\n",
        "    keypoints_norm = (keypoints_array - [box[0], box[1]]) / [box[2], box[3]]  # Normalize\n",
        "\n",
        "    # Compute velocity\n",
        "    velocity = np.diff(keypoints_norm, axis=0, prepend=keypoints_norm[:1])  # [frames, 17, 2]\n",
        "\n",
        "    # Load audio features\n",
        "    audio_file = Path(DATADIR) / 'brace' / 'audio_features' / str(row['year']) / row['video_id'] / f\"{row['video_id']}.{row['seq_idx']}.npz\"\n",
        "    if audio_file.exists():\n",
        "        audio_data = np.load(audio_file)\n",
        "        onset_beat = audio_data['onset_beat'].flatten()  # Ensure 1D array\n",
        "        if len(onset_beat) > 1:  # Ensure enough points for interpolation\n",
        "            onset_beat = np.interp(\n",
        "                np.arange(len(keypoints_norm)),\n",
        "                np.linspace(0, len(onset_beat)-1, len(onset_beat)),\n",
        "                onset_beat\n",
        "            )  # Align to keypoint frames\n",
        "            onset_beat = onset_beat[:, np.newaxis, np.newaxis]  # [frames, 1, 1]\n",
        "            x = np.concatenate([keypoints_norm.reshape(-1, 17*2), velocity.reshape(-1, 17*2), onset_beat.reshape(-1, 1)], axis=1)  # [frames, 69]\n",
        "        else:\n",
        "            x = np.concatenate([keypoints_norm.reshape(-1, 17*2), velocity.reshape(-1, 17*2)], axis=1)  # [frames, 68]\n",
        "    else:\n",
        "        x = np.concatenate([keypoints_norm.reshape(-1, 17*2), velocity.reshape(-1, 17*2)], axis=1)  # [frames, 68]\n",
        "\n",
        "    x = torch.tensor(x, dtype=torch.float)\n",
        "    y = torch.tensor(row['dance_type_id'], dtype=torch.long)\n",
        "    data = Data(x=x, edge_index=edge_index, y=y)\n",
        "    data_list.append(data)"
      ],
      "metadata": {
        "id": "-HJ01Mmc0CfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#standard training loop for a PyTorch model, including forward and backward\n",
        "#passes, optimizer steps, and periodic evaluation on a validation set.\n",
        "\n",
        "# GCN model\n",
        "class GCN(torch.nn.Module): #The base class for all neural network model\n",
        "    def __init__(self):\n",
        "        super(GCN, self).__init__()\n",
        "        #First graph convolutional layer\n",
        "        self.conv1 = GCNConv(69, 64)  # 34 (keypoints) + 34 (velocity) + 1 (onset_beat)\n",
        "        #Second graph convolutional layer\n",
        "        self.conv2 = GCNConv(64, 3)   # 3 classes\n",
        "\n",
        "    def forward(self, data):#data flows through the network\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch  # Add batch for batched graphs\n",
        "        x = torch.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        # Pool per graph in batch using global_mean_pool\n",
        "        from torch_geometric.nn import global_mean_pool\n",
        "        x = global_mean_pool(x, batch)  # Shape: [batch_size, 3]\n",
        "        return x\n",
        "\n",
        "# Train\n",
        "model = GCN().to('cuda')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)#Adam optimizer,\n",
        "#lr: learning rate\n",
        "criterion = torch.nn.CrossEntropyLoss()#Loss function\n",
        "loader = DataLoader(data_list[:24], batch_size=4, shuffle=True)  # 80% train\n",
        "val_loader = DataLoader(data_list[24:], batch_size=4)  # 20% val, validation data\n",
        "\n",
        "#set the model to training mode\n",
        "model.train()\n",
        "for epoch in range(5):\n",
        "    for data in loader:\n",
        "        data = data.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)  # Shape: [batch_size, 3] (e.g., [4, 3])\n",
        "        loss = criterion(out, data.y)  # data.y is [batch_size] (e.g., [4])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    # Validate\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in val_loader:\n",
        "        data = data.to('cuda')\n",
        "        out = model(data)\n",
        "        pred = out.argmax(dim=1)  # Predict per batch\n",
        "        correct += (pred == data.y).sum().item()\n",
        "        total += len(data.y)\n",
        "    print(f\"Epoch {epoch+1}, Val Accuracy: {correct/total:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3Ncn5exkbVv",
        "outputId": "4e82e061-d32a-4816-953b-7cabae72f2c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Val Accuracy: 0.50\n",
            "Epoch 2, Val Accuracy: 0.17\n",
            "Epoch 3, Val Accuracy: 0.33\n",
            "Epoch 4, Val Accuracy: 0.50\n",
            "Epoch 5, Val Accuracy: 0.67\n"
          ]
        }
      ]
    }
  ]
}